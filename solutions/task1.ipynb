{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6a01151",
   "metadata": {},
   "source": [
    "# Task 1: Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33334d69",
   "metadata": {},
   "source": [
    "#### 1. Download the BBC dataset provided on Moodle. The dataset, created by Greene and Cunningham, 2006 is a collection of 2225 documents from the BBC news website already categorized into 5 classes: business, entertainment, politics, sport, and tech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a2d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business', 'entertainment', 'politics', 'README.TXT', 'sport', 'tech']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# The dataset can be found in the /data/BBC folder\n",
    "print(os.listdir(\"../data/BBC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42442b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of instances in each class {'business': 510, 'entertainment': 386, 'politics': 417, 'sport': 511, 'tech': 401}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to hold the number of instances of each class\n",
    "# business/entertainment/politics/sport/tech\n",
    "category_dict = dict()\n",
    "\n",
    "category_dict[\"business\"] = len(os.listdir(\"../data/BBC/business\"))\n",
    "category_dict[\"entertainment\"] = len(os.listdir(\"../data/BBC/entertainment\"))\n",
    "category_dict[\"politics\"] = len(os.listdir(\"../data/BBC/politics\"))\n",
    "category_dict[\"sport\"] = len(os.listdir(\"../data/BBC/sport\"))\n",
    "category_dict[\"tech\"] = len(os.listdir(\"../data/BBC/tech\"))\n",
    "\n",
    "print(\"The number of instances in each class\", category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30f8ae63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Texts: 2225\n"
     ]
    }
   ],
   "source": [
    "num_texts = 0\n",
    "\n",
    "for value in category_dict.values():\n",
    "    num_texts += value\n",
    "print('Total Number of Texts: {num_texts}'.format(num_texts=num_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f484909",
   "metadata": {},
   "source": [
    "#### 2. Plot the distribution of the instances in each class and save the graphic in a file called BBC-distribution.pdf. You may want to use matplotlib.pyplot and savefig to do this. This pre-analysis of the data set will allow you to determine if the classes are balanced, and which metric is more appropriate to use to evaluate the performance of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47293d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "categories = list(category_dict.keys())\n",
    "instances = list(category_dict.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "# Creating the bar plot\n",
    "plt.bar(categories, instances, color ='powderblue', width = 0.6)\n",
    " \n",
    "plt.xlabel(\"Text Categories\")\n",
    "plt.ylabel(\"No. of Instances\")\n",
    "plt.title(\"Distribution of Instances in Each Class\")\n",
    "plt.savefig(\"../output/BBC-distribution.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18330d3d",
   "metadata": {},
   "source": [
    "#### 3. Load the corpus using load files and make sure you set the encoding to latin1. This will read the file structure and assign the category name to each file from their parent directory name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b11d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "\n",
    "# Reads the file structure and assign the category name to each file from their parent directory name\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_files.html\n",
    "res = load_files(\"../data/BBC\", encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd45fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The raw text data to learn (list of str)\n",
    "X = res.data\n",
    "\n",
    "# The target labels (e.g. business/entertainment/politics/sport/tech) but as an integer index! (e.g. 0/1/2/3/4)\n",
    "y = res.target\n",
    "\n",
    "target_names = res.target_names\n",
    "print(\"The names of target classes: \", target_names)\n",
    "\n",
    "print(\"\\nSome examples below: \")\n",
    "for i in range(0,10):\n",
    "    text = res.data[i]\n",
    "    target = res.target[i]\n",
    "    category = target_names[target]\n",
    "    print('{text}...{category}'.format(text=text[0:30], category=category))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c3b86",
   "metadata": {},
   "source": [
    "#### 5. Split the dataset into 80% for training and 20% for testing. For this, you must use train test split with the parameter random state set to None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a05b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05913df",
   "metadata": {},
   "source": [
    "#### 4. Pre-process the dataset to have the features ready to be used by a multinomial Naive Bayes classifier. This means that the frequency of each word in each class must be computed and stored in a term-document matrix. For this, you can use feature extraction.text.CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee6f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Convert a collection of text documents to a matrix of token counts. (\"Tokenization\")\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# Xarray of shape (n_samples, n_features)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "print(\"Shape of X_train_counts: \", X_train_counts.shape)\n",
    "print(\"y_train length: \", len(y_train))\n",
    "\n",
    "print(\"\\nVocabulary (A Mapping of Terms to Feature Indices)\")\n",
    "vocabulary = count_vect.vocabulary_\n",
    "names = list(vocabulary.keys())\n",
    "index = list(vocabulary.values())\n",
    "for i in range(0,10):\n",
    "    print(names[i] + \":\",index[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba4bd64",
   "metadata": {},
   "source": [
    "#### 6. Train a multinomial Naive Bayes Classifier (naive bayes.MultinomialNB) on the training set using the default parameters and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multinomialNB = MultinomialNB()\n",
    "clf = multinomialNB.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a29dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Let's test with a few examples to see if the model makes sense...\\n\")\n",
    "\n",
    "docs_new = ['MSFT stock hit $300', 'Intel core processor with 16GB RAM', \"GO HABS GO!\"]\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "\n",
    "predicted = clf.predict(X_new_counts)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2998cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's actually test the model using X_text, y_test\n",
    "\n",
    "X_test_counts = count_vect.transform(X_test)\n",
    "\n",
    "y_predicted = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92c54e8",
   "metadata": {},
   "source": [
    "#### 7. In a file called bbc-performance.txt, save the following information: (to make it easier for the TAs, make sure that your output for each sub-question below is clearly marked in your output file, using the headings (a), (b) . . .)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdb48e4",
   "metadata": {},
   "source": [
    "##### (a) a clear separator (a sequence of hyphens or stars) and string clearly describing the model (e.g. “MultinomialNB default values, try 1”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3900ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create files that can be appended to\n",
    "file_performance = open(\"../output/bbc-performance.txt\", \"a\")\n",
    "file_discussion = open(\"../output/bbc-discussion.txt\", \"a\")\n",
    "\n",
    "# Clear contents\n",
    "file_performance.truncate(0)\n",
    "file_discussion.truncate(0)\n",
    "\n",
    "def write_model_name_to_file(model_name):\n",
    "    file_performance.write(\"\\n(a) **** {model_name} ****\\n\\n\".format(model_name=model_name))\n",
    "\n",
    "write_model_name_to_file(\"MultinomialNB default values, try 1\")\n",
    "print(\"Writing to file...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5aeef6",
   "metadata": {},
   "source": [
    "##### (b) the confusion matrix (you can use confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f8b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "def print_confusion_matrix(cf_matrix):\n",
    "    print('Confusion Matrix:\\n {cf_matrix}'.format(cf_matrix=cf_matrix))\n",
    "    \n",
    "def write_confusion_matrix_to_file(cf_matrix):\n",
    "    file_performance.write(\"(b) Confusion Matrix\" + \"\\n\\n\")\n",
    "    np.savetxt(file_performance, X=cf_matrix.astype(int), fmt ='%i\\t')\n",
    "    file_performance.write(\"\\n\")\n",
    "    \n",
    "print_confusion_matrix(cf_matrix)\n",
    "write_confusion_matrix_to_file(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa20e08",
   "metadata": {},
   "source": [
    "##### (c) the precision, recall, and F1-measure for each class (you can use classification report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648f6a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def print_classification_report(y_test, y_predicted, target_names):\n",
    "    report = metrics.classification_report(y_test, y_predicted, target_names=target_names)\n",
    "    print(report)\n",
    "    \n",
    "def write_classification_report_to_file(y_test, y_predicted, target_names):\n",
    "    report = metrics.classification_report(y_test, y_predicted, target_names=target_names)\n",
    "    file_performance.write(\"(c) Classification Report\\n\\n\" + report)\n",
    "    file_performance.write(\"\\n\")\n",
    "    \n",
    "print_classification_report(y_test, y_predicted, target_names)\n",
    "write_classification_report_to_file(y_test, y_predicted, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177baca",
   "metadata": {},
   "source": [
    "##### (d) the accuracy, macro-average F1 and weighted-average F1 of the model (you can use accuracy score and f1 score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a92ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def print_scores(y_test,y_predicted):\n",
    "    print(\"Accuracy Score: \", accuracy_score(y_test, y_predicted))\n",
    "    print(\"Macro-Average F1: \", f1_score(y_test, y_predicted, average=\"macro\"))\n",
    "    print(\"Weighted-Average F1: \", f1_score(y_test, y_predicted, average=\"weighted\"))\n",
    "    \n",
    "def write_scores_to_file(y_test,y_predicted):\n",
    "    file_performance.write(\"(d) Accuracy, Macro-Average F1 and Weighted-Average F1\\n\\n\")\n",
    "    file_performance.write(\"Accuracy Score: \" + str(accuracy_score(y_test, y_predicted)) + \"\\n\")\n",
    "    file_performance.write(\"Macro-Average F1: \" + str(f1_score(y_test, y_predicted, average=\"macro\")) + \"\\n\")\n",
    "    file_performance.write(\"Weighted-Average F1: \" + str(f1_score(y_test, y_predicted, average=\"weighted\")) + \"\\n\")\n",
    "    file_performance.write(\"\\n\")\n",
    "\n",
    "print_scores(y_test, y_predicted)\n",
    "write_scores_to_file(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b4a9a7",
   "metadata": {},
   "source": [
    "##### (e) the prior probability of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e524d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dictionary that holds the prior probabilities of each class\n",
    "def compute_prior_probabilities(multinomialNB):\n",
    "    class_count = multinomialNB.class_count_\n",
    "    total = sum(class_count)\n",
    "    prior_dict = dict()\n",
    "    \n",
    "    for i in range(len(class_count)):\n",
    "        target = target_names[i]\n",
    "        probability = class_count[i] / total\n",
    "        prior_dict[target] = round(probability, 4)\n",
    "        \n",
    "    return prior_dict\n",
    "\n",
    "def print_class_count(multionomialNB):\n",
    "    class_count = multinomialNB.class_count_\n",
    "    total = sum(class_count)\n",
    "    print(\"The number of samples encountered for each class: {class_count}\".format(class_count=class_count))\n",
    "    print(\"The total number of samples: {total}\".format(total=total))\n",
    "    \n",
    "def print_prior_probabilities(multinomialNB):\n",
    "    prior_dict = compute_prior_probabilities(multinomialNB)\n",
    "    print(\"The prior probabilities of each class: {prior_dict}\".format(prior_dict=prior_dict))\n",
    "    \n",
    "def write_prior_probabilities_to_file(multinomialNB):\n",
    "    file_performance.write(\"(e) Prior Probability of Each Class F1\\n\\n\")\n",
    "    prior_dict = compute_prior_probabilities(multinomialNB)\n",
    "    for key in prior_dict:\n",
    "        category = key\n",
    "        probability = prior_dict[key]\n",
    "        file_performance.write(\"{category}: {probability:.4f}\".format(category=category, probability=probability))\n",
    "        file_performance.write(\"\\n\")\n",
    "    file_performance.write(\"\\n\")\n",
    "    \n",
    "print_class_count(multinomialNB)\n",
    "print_prior_probabilities(multinomialNB)\n",
    "write_prior_probabilities_to_file(multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf35119",
   "metadata": {},
   "source": [
    "##### (f) the size of the vocablary (i.e. the number of different words). For example, if the word potato appears 3 times, you only count it once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2def2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(vocabulary.keys())\n",
    "\n",
    "def print_vocabulary_size(multinomialNB):\n",
    "    print(\"The size of the vocabulary: {vocabulary_size}\\n\".format(vocabulary_size = vocabulary_size))\n",
    "    print(\"Note that this can also be deduced by the number of columns (features) in the document-term matrix: \", X_train_counts.shape[1])\n",
    "    print(\"Or this can be computed from the feature counts of the MultionomialNB: \", multinomialNB.feature_count_.shape[1])\n",
    "\n",
    "def write_vocabulary_size_to_file(multinomialNB):\n",
    "    file_performance.write(\"(f) The Size of the Vocablary\\n\")\n",
    "    # The number of columns in the term document matrix\n",
    "    vocabulary_size = multinomialNB.feature_count_.shape[1]\n",
    "    file_performance.write(\"The size of the vocabulary: {vocabulary_size}\\n\".format(vocabulary_size = vocabulary_size))\n",
    "    file_performance.write(\"\\n\")\n",
    "\n",
    "print_vocabulary_size(multinomialNB)\n",
    "write_vocabulary_size_to_file(multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5ec8ed",
   "metadata": {},
   "source": [
    "##### (g) the number of word-tokens in each class (i.e. the number of words in total). For example, if the word potato appears 3 times, you count it 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6103845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a dictionary containing the number of word-tokens in each class\n",
    "def compute_word_token_dict(multinomialNB):\n",
    "    word_token_dict = dict()\n",
    "    class_count = multinomialNB.class_count_\n",
    "    feature_count = multinomialNB.feature_count_\n",
    "    \n",
    "    for i in range(len(class_count)):\n",
    "        target = target_names[i]\n",
    "        # Take the sum of all the words for that class\n",
    "        word_token_dict[target] = sum(feature_count[i, :])\n",
    "        \n",
    "    return word_token_dict\n",
    "    \n",
    "def print_word_tokens_by_class(multinomialNB):\n",
    "    word_token_dict = compute_word_token_dict(multinomialNB)\n",
    "    print(\"The number of word tokens by class: \", word_token_dict)\n",
    "    \n",
    "def write_word_tokens_by_class_to_file(multinomialNB):\n",
    "    file_performance.write(\"(g) The number of word-tokens in each class (i.e. the number of words in total)\\n\")\n",
    "    word_token_dict = compute_word_token_dict(multinomialNB)\n",
    "    file_performance.write(\"The number of word tokens by class: \" +  str(word_token_dict))\n",
    "    file_performance.write(\"\\n\\n\")\n",
    "\n",
    "print_word_tokens_by_class(multinomialNB)\n",
    "write_word_tokens_by_class_to_file(multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c92c7e2",
   "metadata": {},
   "source": [
    "##### (h) the number of word-tokens in the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed95f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_word_tokens(multinomialNB):\n",
    "    feature_count = multinomialNB.feature_count_\n",
    "    return feature_count.sum()\n",
    "    \n",
    "def print_word_tokens_total(multinomialNB):\n",
    "    total = compute_total_word_tokens(multinomialNB)\n",
    "    print(\"Total word-tokens in the corpus: \", total)\n",
    "\n",
    "def write_word_tokens_total_to_file(multinomialNB):\n",
    "    file_performance.write(\"(h) The number of word-tokens in the entire corpus\\n\")\n",
    "    total = compute_total_word_tokens(multinomialNB)\n",
    "    file_performance.write(\"Total word-tokens in the corpus: \" + str(total))\n",
    "    file_performance.write(\"\\n\\n\")\n",
    "    \n",
    "print_word_tokens_total(multinomialNB)\n",
    "write_word_tokens_total_to_file(multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf2cb29",
   "metadata": {},
   "source": [
    "##### (i) the number and percentage of words with a frequency of zero in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca10b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_count_and_percentage(x, y, class_name):\n",
    "    print(\"Count for {class_name}: {count}\".format(class_name=class_name, count=x))\n",
    "    print(\"Percentage for {class_name}: {percentage:.2%}\".format(class_name=class_name, percentage=x/y))\n",
    "    print(\"\\n\")\n",
    "\n",
    "def write_count_and_percentage_to_file(x, y, class_name):\n",
    "    file_performance.write(\"Count for {class_name}: {count}\".format(class_name=class_name, count=x))\n",
    "    file_performance.write(\"\\n\")\n",
    "    file_performance.write(\"Percentage for {class_name}: {percentage:.2%}\".format(class_name=class_name, percentage=x/y))\n",
    "    file_performance.write(\"\\n\")\n",
    "    \n",
    "# returns a dictionary containing the number of words with a frequency zero in each class\n",
    "def compute_frequency_zero_words(multinomialNB):\n",
    "    frequency_zero_dict = dict()\n",
    "    feature_count = multinomialNB.feature_count_\n",
    "    num_features = feature_count.shape[1]\n",
    "    \n",
    "    for i in range(len(target_names)):\n",
    "        target = target_names[i]\n",
    "        count_zero = num_features - np.count_nonzero(feature_count[i,:])\n",
    "        frequency_zero_dict[target] = count_zero\n",
    "        \n",
    "    return frequency_zero_dict\n",
    "    \n",
    "def print_words_with_frequency_zero(multinomialNB):\n",
    "    feature_count = multinomialNB.feature_count_\n",
    "    num_features = feature_count.shape[1]\n",
    "    frequency_zero_dict = compute_frequency_zero_words(multinomialNB)\n",
    "    print(\"Recall that the number of features is: {num_features}\".format(num_features = num_features))\n",
    "    print(\"The number and percentage of words with a frequency of ZERO in each class is outlined below\\n\")\n",
    "    \n",
    "    for key in frequency_zero_dict:\n",
    "        print_count_and_percentage(frequency_zero_dict[key], num_features, key)\n",
    "    \n",
    "def write_words_with_frequency_zero_to_file(multinomialNB):\n",
    "    file_performance.write(\"(i) the number and percentage of words with a frequency of zero in each class\\n\")\n",
    "    feature_count = multinomialNB.feature_count_\n",
    "    num_features = feature_count.shape[1]\n",
    "    frequency_zero_dict = compute_frequency_zero_words(multinomialNB)\n",
    "    \n",
    "    for key in frequency_zero_dict:\n",
    "        write_count_and_percentage_to_file(frequency_zero_dict[key], num_features, key)\n",
    "        \n",
    "    file_performance.write(\"\\n\")\n",
    "    \n",
    "print_words_with_frequency_zero(multinomialNB)\n",
    "write_words_with_frequency_zero_to_file(multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91956559",
   "metadata": {},
   "source": [
    "##### (j) the number and percentage of words with a frequency of one in the entire corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cd29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_words_with_frequency_one(multinomialNB):\n",
    "    feature_count = multinomialNB.feature_count_\n",
    "    num_features = feature_count.shape[1]\n",
    "    total = 0\n",
    "    \n",
    "    for j in range(num_features):\n",
    "        col = feature_count[:, j]\n",
    "        col_sum = int(col.sum())\n",
    "        \n",
    "        if (col_sum == 1):\n",
    "            total += 1\n",
    "        \n",
    "    return total\n",
    "\n",
    "def print_num_words_with_frequency_one(multinomialNB):\n",
    "    total = get_num_words_with_frequency_one(multinomialNB)\n",
    "    vocabulary_size = multinomialNB.feature_count_.shape[1]\n",
    "    print(\"The number of words with a frequency of one in the entire corpus: \", total)\n",
    "    print(\"The percentage of words with a frequency of one in the entire corpus: {percentage:.2%}\".format(percentage=(total/vocabulary_size)))\n",
    "    print(\"(Note that the number of features is: \" + str(vocabulary_size) + \")\")\n",
    "    \n",
    "def write_num_words_with_frequency_one_to_file(multinomialNB):\n",
    "    total = get_num_words_with_frequency_one(multinomialNB)\n",
    "    vocabulary_size = multinomialNB.feature_count_.shape[1]\n",
    "    file_performance.write(\"(j) the number and percentage of words with a frequency of one in the entire corpus\\n\")\n",
    "    file_performance.write(\"The number of words: \" + str(total))\n",
    "    file_performance.write(\"\\n\")\n",
    "    file_performance.write(\"The percentage of words: {percentage:.2%}\".format(percentage=(total/vocabulary_size)))\n",
    "    file_performance.write(\"\\n\\n\")\n",
    "    \n",
    "get_num_words_with_frequency_one(multinomialNB)\n",
    "print_num_words_with_frequency_one(multinomialNB)\n",
    "write_num_words_with_frequency_one_to_file(multinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efd3ff2",
   "metadata": {},
   "source": [
    "##### (k) your 2 favorite words (that are present in the vocabulary) and their log-prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221575d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Index of word 'executive': {index}\".format(index = vocabulary[\"executive\"]))\n",
    "print(\"Index of word 'the': {index}\".format(index = vocabulary[\"the\"]))\n",
    "\n",
    "def compute_favorite_words_log_prob(multinomialNB):\n",
    "    feature_index_1 = vocabulary[\"executive\"]\n",
    "    feature_index_2 = vocabulary[\"the\"]\n",
    "    p1 = multinomialNB.feature_log_prob_\n",
    "    log_prob_1 = sum(p1[:, feature_index_1])\n",
    "    log_prob_2 = sum(p1[:, feature_index_2])\n",
    "    return log_prob_1, log_prob_2\n",
    "\n",
    "def print_log_prob(multinomialNB):\n",
    "    log_prob_1, log_prob_2 = compute_favorite_words_log_prob(multinomialNB)\n",
    "    print(\"\\n\")\n",
    "    print(\"log_prob of word 'executive': \", str(log_prob_1))\n",
    "    print(\"log_prob of word 'the': \", str(log_prob_2))\n",
    "    \n",
    "def write_log_prob_to_file(multinomialNB):\n",
    "    log_prob_1, log_prob_2 = compute_favorite_words_log_prob(multinomialNB)\n",
    "    file_performance.write(\"(k) your 2 favorite words (that are present in the vocabulary) and their log-prob\\n\")\n",
    "    file_performance.write(\"log_prob of word 'executive': \" + str(log_prob_1))\n",
    "    file_performance.write(\"\\n\")\n",
    "    file_performance.write(\"log_prob of word 'the': \" + str(log_prob_2))\n",
    "    file_performance.write(\"\\n\")\n",
    "\n",
    "print_log_prob(multinomialNB)\n",
    "write_log_prob_to_file(multinomialNB)\n",
    "\n",
    "# Makes sense that the log_prob of \"the\" is higher than the log_prob of \"executive\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd09b6",
   "metadata": {},
   "source": [
    "#### 8. Redo steps 6 and 7 without changing anything (do not redo step 5, the dataset split). Change the model name to something like “MultinomialNB default values, try 2” and append the results to the file bbc-performance.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_separator_to_file():\n",
    "    file_performance.write(\"\\n---------------------------------------------------------------------\\n\")\n",
    "\n",
    "def write_model_to_file(model_name, cf_matrix, y_test, y_predicted, target_names, multinomialNB):\n",
    "    write_separator_to_file()\n",
    "    write_model_name_to_file(model_name)\n",
    "    write_confusion_matrix_to_file(cf_matrix)\n",
    "    write_classification_report_to_file(y_test, y_predicted, target_names)\n",
    "    write_scores_to_file(y_test, y_predicted)\n",
    "    write_prior_probabilities_to_file(multinomialNB)\n",
    "    write_vocabulary_size_to_file(multinomialNB)\n",
    "    write_word_tokens_by_class_to_file(multinomialNB)\n",
    "    write_word_tokens_total_to_file(multinomialNB)\n",
    "    write_words_with_frequency_zero_to_file(multinomialNB)\n",
    "    write_num_words_with_frequency_one_to_file(multinomialNB)\n",
    "    write_log_prob_to_file(multinomialNB)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4968bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multinomialNB(smoothing, X_train_counts, X_test, y_train, y_test, y_predicted, target_names, title):\n",
    "    multinomialNB = MultinomialNB(alpha = smoothing)\n",
    "    clf = multinomialNB.fit(X_train_counts, y_train)\n",
    "    y_predicted = clf.predict(count_vect.transform(X_test))\n",
    "\n",
    "    cf_matrix = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "    print(str(cf_matrix) + \"\\n\")\n",
    "    print_classification_report(y_test, y_predicted, target_names)\n",
    "    print_scores(y_test, y_predicted)\n",
    "    write_model_to_file(title, cf_matrix, y_test, y_predicted, target_names, multinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3d9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial NB, default values, take #2\n",
    "\n",
    "create_multinomialNB(title = \"MultinomialNB default values, try 2\",\n",
    "                     smoothing = 1.0, # default smoothing  = 1.0 as per sklearn documentation \n",
    "                     X_train_counts = X_train_counts, \n",
    "                     X_test = X_test, \n",
    "                     y_train = y_train,\n",
    "                     y_test = y_test,\n",
    "                     y_predicted = y_predicted, \n",
    "                     target_names = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0245b205",
   "metadata": {},
   "source": [
    "#### 9. Redo steps 6 and 7 again, but this time, change the smoothing value to 0.0001. Append the results at the end of bbc-performance.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_multinomialNB(title = \"MultinomialNB (smoothing = 0.0001)\",\n",
    "                     smoothing = 0.0001,\n",
    "                     X_train_counts = X_train_counts, \n",
    "                     X_test = X_test, \n",
    "                     y_train = y_train,\n",
    "                     y_test = y_test,\n",
    "                     y_predicted = y_predicted, \n",
    "                     target_names = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342ae9d",
   "metadata": {},
   "source": [
    "#### 10. Redo steps 6 and 7, but this time, change the smoothing value to 0.9. Append the results at the end of bbc-performance.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fc129",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_multinomialNB(title = \"MultinomialNB (smoothing = 0.9)\",\n",
    "                     smoothing = 0.9,\n",
    "                     X_train_counts = X_train_counts, \n",
    "                     X_test = X_test, \n",
    "                     y_train = y_train,\n",
    "                     y_test = y_test,\n",
    "                     y_predicted = y_predicted, \n",
    "                     target_names = target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92bf18b",
   "metadata": {},
   "source": [
    "#### 11. In a separate plain text file called bbc-discussion.txt, explain in 1 to 2 paragraphs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66e8c9",
   "metadata": {},
   "source": [
    "##### (a) what metric is best suited to this dataset/task and why (see step (2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b646672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question11_a = \"\"\" \n",
    "(a) \n",
    "\n",
    "First and foremost, it is necessary to discuss the class balance of business/entertainment/politics/sport/tech\n",
    "As illustrated in the first section, the classes are MOSTLY balanced (with some minor discrepancies)\n",
    "\n",
    "Thus, it can be said that accuracy along with F1 measure (macro and weighted) are suitable measures for this dataset.\n",
    "\n",
    "This is highlighted by the fact that the accuracy score, macro-average F1, and weighted-average F1 all\n",
    "have a similar result of 0.97-0.98!\n",
    "\n",
    "If it was the case that there is a major class imbalance, weighted-average F1 would be much more suitable in\n",
    "order to account for the classes that are represented less.\n",
    "\n",
    "-----------------------------------------------------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "def print_discussion(text):\n",
    "    print(text)\n",
    "    \n",
    "def write_discussion_to_file(text):\n",
    "    file_discussion.write(text)\n",
    "    \n",
    "\n",
    "print_discussion(question11_a)\n",
    "write_discussion_to_file(\"Question 11\\n\")\n",
    "write_discussion_to_file(question11_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d61f3",
   "metadata": {},
   "source": [
    "##### (b) why the performance of steps (8-10) are the same or are different than those of step (7) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "question11_b = \"\"\"\n",
    "(b)\n",
    "\n",
    "There are many interesting observations that can be drawn from steps 8-10. First and foremost, it is important\n",
    "to note that step 8 (MultinomialNB with default values) yielded the same results as step 6. \n",
    "--> This is expected behavior given that we kept the same values and did not redo the test split!\n",
    "\n",
    "Moreover, the performance of the MultinomialNB models were very similar for steps (8-10). All the models achieved\n",
    "a similar performance in terms of accuracy, macro-average F1, and weighted-average F1. \n",
    "(There is a very small differences in the confusion matrices).\n",
    "\n",
    "Lastly, a small change that can be observed is in the feature log probabilities of the words (Question #7 (k)) \n",
    "when changing the smoothing values.\n",
    "\n",
    "Note that this is expected, since smoothing was applied!!!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print_discussion(question11_b)\n",
    "write_discussion_to_file(question11_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_performance.close()\n",
    "file_discussion.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
